# Chat-Ollama LangChain Template

This template provides a starting point for building LangChain applications that utilize a local Ollama API for natural language processing. 

The template includes a Python Flask server that handles API requests and a responsive web-based chat interface.

## Features

- **Local Ollama API Integration**: Communicate with LLMs locally without the need for external API calls.

## Prerequisites

- Python 3.8 or newer
- Flask
- Ollama installed locally

## Installation

- Install Python deps and run the server. Double click the index.html file to open chat in a browser.